{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2469ca-368b-4af0-af88-6e47abf78ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What tasks can Hugging Face Transformers perform?\n",
      "Answer: classification, information extraction, \n",
      "question answering, summarization, translation\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load pretrained QA model\n",
    "qa = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "# Example context\n",
    "context = \"\"\"\n",
    "The Hugging Face Transformers library provides thousands of pretrained models\n",
    "to perform tasks on texts such as classification, information extraction, \n",
    "question answering, summarization, translation, and text generation.\n",
    "\"\"\"\n",
    "\n",
    "# Ask a question\n",
    "question = \"What tasks can Hugging Face Transformers perform?\"\n",
    "\n",
    "# Get answer\n",
    "result = qa(question=question, context=context)\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", result['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11607964-bd80-4bd8-bfc8-c1a9999ee15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "def answer_question(context, question):\n",
    "    result = qa(question=question, context=context)\n",
    "    return result['answer']\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=answer_question,\n",
    "    inputs=[\"text\", \"text\"],\n",
    "    outputs=\"text\",\n",
    "    title=\"ðŸ§  Simple Question Answering Bot\",\n",
    "    description=\"Ask a question based on the provided context!\"\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790542e-eba4-418b-8cac-f36b6320426f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc08265-d650-4240-aecb-488b7e780941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
