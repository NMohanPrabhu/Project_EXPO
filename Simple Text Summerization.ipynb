{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "257c0b4e-3adc-48cb-99ec-09c4666d42d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "All PyTorch model weights were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\gradio\\queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\gradio\\blocks.py\", line 1935, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\gradio\\blocks.py\", line 1520, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\gradio\\utils.py\", line 826, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_13568\\1419755315.py\", line 11, in summarize_text\n",
      "    summary = summarizer(text, max_length=100, min_length=30, do_sample=False)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 274, in __call__\n",
      "    return super().__call__(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 167, in __call__\n",
      "    result = super().__call__(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 1302, in __call__\n",
      "    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 1309, in run_single\n",
      "    model_outputs = self.forward(model_inputs, **forward_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 1204, in forward\n",
      "    model_outputs = self._forward(model_inputs, **forward_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 196, in _forward\n",
      "    output_ids = self.model.generate(**model_inputs, **generate_kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\transformers\\generation\\tf_utils.py\", line 816, in generate\n",
      "    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\transformers\\generation\\tf_utils.py\", line 1071, in _prepare_encoder_decoder_kwargs_for_generation\n",
      "    encoder_outputs = encoder(**encoder_kwargs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 437, in run_call_with_unpacked_inputs\n",
      "    return func(self, **unpacked_inputs)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\transformers\\models\\bart\\modeling_tf_bart.py\", line 833, in call\n",
      "    embed_pos = self.embed_positions(input_shape)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\N_38\\lib\\site-packages\\transformers\\models\\bart\\modeling_tf_bart.py\", line 143, in call\n",
      "    return super().call(position_ids + tf.constant(self.offset, dtype=offset_dtype))\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling layer \"embed_positions\" \"                 f\"(type TFBartLearnedPositionalEmbedding).\n",
      "\n",
      "{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[3699] = 3701 is not in [0, 1026) [Op:ResourceGather]\n",
      "\n",
      "Call arguments received by layer \"embed_positions\" \"                 f\"(type TFBartLearnedPositionalEmbedding):\n",
      "  ‚Ä¢ input_shape=['tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)']\n",
      "  ‚Ä¢ past_key_values_length=0\n",
      "  ‚Ä¢ position_ids=None\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load summarization model\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Function for Gradio app\n",
    "def summarize_text(text):\n",
    "    if len(text.strip()) == 0:\n",
    "        return \"‚ö†Ô∏è Please enter some text.\"\n",
    "    summary = summarizer(text, max_length=100, min_length=30, do_sample=False)\n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "# Gradio Interface\n",
    "demo = gr.Interface(\n",
    "    fn=summarize_text,\n",
    "    inputs=gr.Textbox(lines=10, placeholder=\"Paste your text here...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"üìù Simple Text Summarizer\",\n",
    "    description=\"Paste an article, paragraph, or document and get a concise summary using Hugging Face Transformers.\"\n",
    ")\n",
    "\n",
    "# Launch app\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b075ae5-931d-4d93-bf3f-065c5990f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf1b728-58c3-410f-a4a1-804e6cb68107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
